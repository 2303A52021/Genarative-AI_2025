{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP427AtC1jqlrBcnWLeRbLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52021/Genarative-AI_2025/blob/main/GENERATIVE_AI_LAB_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 1:\n"
      ],
      "metadata": {
        "id": "SHdLplu5DTuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "y_true = np.array([20,30,40,50,60])\n",
        "y_pred = np.array([20.5,30.3,40.2,50.6,60.7])\n",
        "def calculate_error_metrics(y_true,y_pred):\n",
        "    n = len(y_true)\n",
        "    MAE = np.sum(np.abs(y_true-y_pred))/n\n",
        "    MSE = np.sum((y_true - y_pred)**2)/n\n",
        "    RMSE = np.sqrt(MSE)\n",
        "    return MAE,MSE,RMSE\n",
        "MAE_scratch,MSE_scratch,RMSE_scratch = calculate_error_metrics(y_true,y_pred)\n",
        "MAE_lib = mean_absolute_error(y_true,y_pred)\n",
        "MSE_lib = mean_squared_error(y_true,y_pred)\n",
        "RMSE_lib = np.sqrt(MSE_lib)\n",
        "print(\"Error Metrics from Scratch:\")\n",
        "print(f\"MAE: {MAE_scratch}\")\n",
        "print(f\"MSE: {MSE_scratch}\")\n",
        "print(f\"RMSE: {RMSE_scratch}\")\n",
        "print(\"\\nError Metrics using libraries:\")\n",
        "print(f\"MAE: {MAE_lib}\")\n",
        "print(f\"MSE: {MSE_lib}\")\n",
        "print(f\"RMSE: {RMSE_lib}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCcZ-e-p8sfJ",
        "outputId": "7631f6ca-c61c-4756-d9b0-c19918c69c92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Metrics from Scratch:\n",
            "MAE: 0.4600000000000016\n",
            "MSE: 0.24600000000000147\n",
            "RMSE: 0.49598387070549127\n",
            "\n",
            "Error Metrics using libraries:\n",
            "MAE: 0.4600000000000016\n",
            "MSE: 0.24600000000000147\n",
            "RMSE: 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 2"
      ],
      "metadata": {
        "id": "7VqP-o_6DNhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
        "\n",
        "def calculate_evaluation_metrics(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    p = 1\n",
        "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    y_true_mean = np.mean(y_true)\n",
        "    y_pred_mean = np.mean(y_pred)\n",
        "    numerator = np.sum((y_true - y_true_mean) * (y_pred - y_pred_mean))\n",
        "    denominator = np.sum((y_true - y_true_mean) ** 2)\n",
        "    explained_variance = numerator / denominator\n",
        "\n",
        "    return {\n",
        "        'R-squared': r2,\n",
        "        'Adjusted R-squared': adj_r2,\n",
        "        'MAPE': mape,\n",
        "        'Explained Variance': explained_variance\n",
        "    }\n",
        "\n",
        "y_actual = np.array([20, 30, 40, 50, 60])\n",
        "y_pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "\n",
        "metrics = calculate_evaluation_metrics(y_actual, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"-\" * 40)\n",
        "for metric_name, value in metrics.items():\n",
        "    print(f\"{metric_name:20s}: {value:>10.4f}\")\n",
        "\n",
        "print(\"\\nLibrary Implementation Comparison:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'R-squared (sklearn)':20s}: {r2_score(y_actual, y_pred):>10.4f}\")\n",
        "print(f\"{'MAPE (sklearn)':20s}: {mean_absolute_percentage_error(y_actual, y_pred)*100:>10.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZCIvUGECqJA",
        "outputId": "1a3db7db-d693-4a7d-ada1-0c389fade4ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "----------------------------------------\n",
            "R-squared           :     0.9988\n",
            "Adjusted R-squared  :     0.9984\n",
            "MAPE                :     1.2733\n",
            "Explained Variance  :     1.0070\n",
            "\n",
            "Library Implementation Comparison:\n",
            "----------------------------------------\n",
            "R-squared (sklearn) :     0.9988\n",
            "MAPE (sklearn)      :     1.2733\n"
          ]
        }
      ]
    }
  ]
}